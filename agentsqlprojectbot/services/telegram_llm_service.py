# services/telegram_llm_service.py
import asyncio
from typing import Tuple, Optional
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from datetime import datetime

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

from models.pydantic_models import Summary, Mail
from memory.telegram_conversation import OptimizedConversationManager
from services.send_email import EmailService
from services.sql_service import SQLService
from services.database_manager import get_database_manager
from utils.prompts import (
    TEMPLATE_INSTRUCTIONS, SCHEMA, SCHEMA_EXAMPLES,
    EMAIL_TEMPLATE, PROMPT_TEMPLATE
)

from services.token_cost_calculator import TokenCostCalculator

load_dotenv()

class TelegramLLMService:
    """Ø®Ø¯Ù…Ø© LLM Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„ØªÙˆØ§Ø² Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¯Ø¹Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ù…Ø¤Ø³Ø³Ø§Øª"""
    
    def __init__(self, max_workers: int = 10):
        # LLMs
        self.llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
        self.small_llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
        
        # Parsers
        self.summary_parser = PydanticOutputParser(pydantic_object=Summary)
        self.mail_parser = PydanticOutputParser(pydantic_object=Mail)
        
        # Services
        self.conversation_manager = OptimizedConversationManager(
            conversations_dir="logs/conversations",
            max_conversations=5
        )
        self.email_service = EmailService()
        
        # Database Manager
        self.db_manager = get_database_manager()
        
        # Thread Pool Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª blocking
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix="LLM_Worker"
        )
        
        # Chains
        self.summary_chain = self._create_summary_chain()
        self.mail_chain = self._create_mail_chain()
        
        # Schema data
        self.schema_text = "\n".join([
            f"{table}: {', '.join(cols)}" 
            for table, cols in SCHEMA.items()
        ])
        self.schema_examples_text = "\n".join([
            f"{table}: {rows}" 
            for table, rows in SCHEMA_EXAMPLES.items()
        ])
        
        # Cache for history
        self._history_cache = {}
        self._cache_lock = asyncio.Lock()
        self._cache_timeout = 60
        
        self.cost_calculator = TokenCostCalculator()
        
        # ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø±Ø§Ø­Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        self._current_conversation_stages = []
    
    def _create_summary_chain(self):
        """Ø¥Ù†Ø´Ø§Ø¡ chain Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"""
        global prompt_summary
        prompt_summary = PromptTemplate(
            template=PROMPT_TEMPLATE,
            input_variables=["schema_text", "history_text", "user_question", "format_instructions"]
        )
        return prompt_summary | self.llm | self.summary_parser
    
    def _create_mail_chain(self):
        """Ø¥Ù†Ø´Ø§Ø¡ chain Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª"""
        global prompt_mail
        prompt_mail = PromptTemplate(
            template=EMAIL_TEMPLATE,
            input_variables=["user_question", "sql_result", 
                           "format_instructions", "history_text", "template_instructions"]
        )
        return prompt_mail | self.llm | self.mail_parser
    
    async def _get_cached_history(self, chat_id: int) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ø¹ caching Ø°ÙƒÙŠ"""
        return await self.conversation_manager.get_cached_history(chat_id)

    async def _generate_summary(
        self, 
        user_question: str, 
        chat_id: int, 
        username: str, 
        timestamp: str,
        database_id: Optional[str] = None
    ) -> Summary:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ SQL query"""
        history_text = await self._get_cached_history(chat_id)
        
        schema_text = self.schema_text
        schema_examples = self.schema_examples_text
    
        input_data = {
            "schema_text": schema_text,
            "schema_examples": schema_examples,
            "history_text": history_text,
            "user_question": user_question,
            "format_instructions": self.summary_parser.get_format_instructions()
        }
        
        loop = asyncio.get_event_loop()
        input_text = prompt_summary.format(**input_data)
        input_tokens = await self.cost_calculator.count_tokens(
            self.llm, 
            input_text, 
            self.executor
        )
        
        summary = await loop.run_in_executor(
            self.executor,
            lambda: self.summary_chain.invoke(input_data)
        )
        
        summary_text = str(summary)
        output_tokens = await self.cost_calculator.count_tokens(
            self.llm,
            summary_text,
            self.executor
        )
        
        print("Summary Generation input - gemini-2.5-flash")
        print("input tokens:", input_tokens)
        print(input_text)
        print("Summary Generation output - gemini-2.5-flash")
        print("output tokens:", output_tokens)
        print(summary_text)
        stage_data = self.cost_calculator.create_stage_record(
            stage_number=1,
            stage_name="Summary Generation",
            model="gemini-2.5-flash",
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        self._current_conversation_stages.append(stage_data)
        
        return summary, history_text
    
    async def _process_sql_query(
        self, 
        summary: Summary, 
        user_question: str, 
        chat_id: int, 
        username: str, 
        timestamp: str,
        database_id: Optional[str] = None
    ) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© SQL query ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""
        if not summary.sql_query:
            return summary.answer or "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©"
        
        if database_id:
            db = await self.db_manager.get_database_instance(database_id)
            if not db:
                return "âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"
            sql_service = SQLService(db=db)
        else:
            return "âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª"
        
        sql_result = await sql_service.execute_async(summary.sql_query)
        
        prompt = f"""
You are a helpful assistant for a Telegram bot.
Use only the following SQL result to answer the user's question.
Do not invent, assume, or estimate anything.

User question: {user_question}
SQL query: {summary.sql_query}
SQL result: {sql_result}

If the SQL result is empty, respond in natural language indicating no records were found.
Provide a clear and concise answer. Use Arabic or English based on the user's question language.
Keep the response suitable for Telegram messaging (not too long, well formatted).
"""
                
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            self.executor,
            lambda: self.small_llm.invoke(prompt)
        )
        
        output_tokens = await self.cost_calculator.count_tokens(
            self.small_llm,
            response.content,
            self.executor
        )
        
        input_tokens = await self.cost_calculator.count_tokens(
            self.small_llm,
            prompt,
            self.executor
        )
        print("SQL Response Generation input - gemini-2.0-flash")
        print("input tokens:", input_tokens)
        print(prompt)
        print("SQL Response Generation output - gemini-2.0-flash")
        print("output tokens:", output_tokens)
        print(response.content)
        stage_data = self.cost_calculator.create_stage_record(
            stage_number=2,
            stage_name="SQL Response Generation",
            model="gemini-2.0-flash",
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        self._current_conversation_stages.append(stage_data)
        
        return response.content
    
    async def _generate_email(
        self, 
        summary: Summary, 
        user_question: str, 
        chat_id: int, 
        username: str, 
        timestamp: str,
        database_id: Optional[str] = None,
        history_text: str = None
    ) -> Mail:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„"""
        tasks = []
        
        if summary.sql_query and database_id:
            db = await self.db_manager.get_database_instance(database_id)
            if db:
                sql_service = SQLService(db=db)
                tasks.append(sql_service.execute_async(summary.sql_query))
            else:
                tasks.append(asyncio.sleep(0))
        
        results = await asyncio.gather(*tasks)
        sql_result = results[0] if len(results) > 0 else None
        
        input_data = {
            "user_question": user_question,
            "history_text": history_text,
            "sql_result": sql_result or "",
            "format_instructions": self.mail_parser.get_format_instructions(),
            "template_instructions": TEMPLATE_INSTRUCTIONS
        }
        
        loop = asyncio.get_event_loop()
        input_text = prompt_mail.format(**input_data)
        input_tokens = await self.cost_calculator.count_tokens(
            self.llm,
            input_text,
            self.executor
        )
        
        mail = await loop.run_in_executor(
            self.executor,
            lambda: self.mail_chain.invoke(input_data)
        )
        
        output_tokens = await self.cost_calculator.count_tokens(
            self.llm,
            str(mail),
            self.executor
        )
        print("Email Generation input - gemini-2.5-flash")
        print("input tokens:", input_tokens)
        print(input_text)
        print("Email Generation output - gemini-2.5-flash")
        print("output tokens:", output_tokens)
        print(str(mail))
        stage_data = self.cost_calculator.create_stage_record(
            stage_number=3,
            stage_name="Email Generation",
            model="gemini-2.5-flash",
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        self._current_conversation_stages.append(stage_data)
        
        return mail
    
    async def handle_question(
        self, 
        user_question: str, 
        username: str, 
        chat_id: int,
        user_id: int = None,
        database_id: Optional[str] = None,
        org_id: Optional[str] = None
    ) -> Tuple[str, Optional[str], Optional[str], int, Optional[Mail], Optional[str]]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø¯Ø¹Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ù…Ø¤Ø³Ø³Ø§Øª"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Ù…Ø³Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self._current_conversation_stages = []
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ
        summary, history_text = await self._generate_summary(
            user_question, chat_id, username, timestamp, database_id
        )
        
        answer = None
        sql_query = summary.sql_query
        sql_result = None
        mail = None
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 2: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        if summary.way and summary.way.lower() == "sqlquery":
            answer = await self._process_sql_query(
                summary, user_question, chat_id, username, timestamp, database_id
            )

        elif summary.way and summary.way.lower() == "email":
            try:
                mail = await self._generate_email(
                    summary, user_question, chat_id, username, timestamp, database_id, history_text
                )
                
                answer = f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ù„Ù„Ù…Ø±Ø³Ù„ Ø¥Ù„ÙŠÙ‡Ù…: {', '.join(mail.email)}"
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„: {e}")
                answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
        
        else:
            answer = summary.answer or "ØªÙ… Ø§Ù„Ø±Ø¯ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©."
        
        if answer is None:
            answer = "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø©"

        # Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚
        save_task = self.conversation_manager.save_context(
            chat_id=chat_id,
            question=user_question,
            answer=answer,
            user_id=user_id,
            username=username,
            sql_query=sql_query,
            sql_result=str(sql_result) if sql_result else None
        )
        
        memory_task = self.conversation_manager.get_memory_length(chat_id)
        
        await save_task
        history_len = await memory_task
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø¤Ø³Ø³Ø© ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        conversation_id = self.cost_calculator.save_conversation(
            chat_id=chat_id,
            user_id=user_id,
            username=username,
            user_question=user_question,
            org_id=org_id,
            database_id=database_id
        )
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        if self._current_conversation_stages and conversation_id:
            total_input_tokens = sum(s["input_tokens"] for s in self._current_conversation_stages)
            total_output_tokens = sum(s["output_tokens"] for s in self._current_conversation_stages)
            total_tokens = sum(s["total_tokens"] for s in self._current_conversation_stages)
            total_input_cost = sum(float(s["cost"]["input"]) for s in self._current_conversation_stages)
            total_output_cost = sum(float(s["cost"]["output"]) for s in self._current_conversation_stages)
            total_cost = sum(float(s["cost"]["total"]) for s in self._current_conversation_stages)
            
            # âœ… Ø­ÙØ¸ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© Ø¹Ù„Ù‰ Ø­Ø¯Ø©
            for stage in self._current_conversation_stages:
                self.cost_calculator.save_stage(
                    conversation_id=conversation_id,
                    chat_id=chat_id,
                    stage_number=stage["stage_number"],
                    stage_name=stage["stage_name"],
                    model=stage["model"],
                    input_tokens=stage["input_tokens"],
                    output_tokens=stage["output_tokens"],
                    total_tokens=stage["total_tokens"],
                    input_cost=float(stage["cost"]["input"]),
                    output_cost=float(stage["cost"]["output"]),
                    total_cost=float(stage["cost"]["total"])
                )
            
            # âœ… Ø­ÙØ¸ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            self.cost_calculator.save_conversation_summary(
                conversation_id=conversation_id,
                chat_id=chat_id,
                total_stages=len(self._current_conversation_stages),
                input_tokens=total_input_tokens,
                output_tokens=total_output_tokens,
                total_tokens=total_tokens,
                input_cost=total_input_cost,
                output_cost=total_output_cost,
                total_cost=total_cost,
                stages=self._current_conversation_stages
            )
            
            # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            for stage in self._current_conversation_stages:
                self.cost_calculator.update_model_usage(
                    chat_id=chat_id,
                    model=stage["model"],
                    input_tokens=stage["input_tokens"],
                    output_tokens=stage["output_tokens"],
                    total_tokens=stage["total_tokens"],
                    input_cost=float(stage["cost"]["input"]),
                    output_cost=float(stage["cost"]["output"]),
                    total_cost=float(stage["cost"]["total"]),
                    org_id=org_id
                )
            
            # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ø­Ù„
            for stage in self._current_conversation_stages:
                self.cost_calculator.update_stage_usage(
                    chat_id=chat_id,
                    stage_name=stage["stage_name"],
                    input_tokens=stage["input_tokens"],
                    output_tokens=stage["output_tokens"],
                    total_tokens=stage["total_tokens"],
                    input_cost=float(stage["cost"]["input"]),
                    output_cost=float(stage["cost"]["output"]),
                    total_cost=float(stage["cost"]["total"]),
                    org_id=org_id
                )
            
            
            # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ù„Ù„ØªÙˆÙƒÙ†Ø§Øª ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ
            print(f"\nðŸ“Š Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª:")
            print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª: {total_tokens}")
            print(f"   â€¢ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ:")
            print(f"     - Input: ${total_input_cost:.8f}")
            print(f"     - Output: ${total_output_cost:.8f}")
            print(f"     - Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: ${total_cost:.8f}")
            print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø­Ù„: {len(self._current_conversation_stages)}")
            if org_id:
                print(f"   â€¢ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©: {org_id}")
            if database_id:
                print(f"   â€¢ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {database_id}")
            print()

        return answer, sql_query, sql_result, history_len, mail

    async def send_email(self, mail: Mail) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø¥ÙŠÙ…ÙŠÙ„ Ø¨Ø´ÙƒÙ„ async"""
        return await self.email_service.send_async(
            subject=mail.subject,
            body=mail.body,
            recipients=mail.email
        )
    
    async def cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        await self.conversation_manager.stop_writer()
        self.executor.shutdown(wait=True)


# Singleton instance
_llm_service = None

def get_llm_service() -> TelegramLLMService:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ instance ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø©"""
    global _llm_service
    if _llm_service is None:
        _llm_service = TelegramLLMService(max_workers=10)
    return _llm_service