# # services/telegram_llm_service.py
# import asyncio
# from typing import Tuple, Optional
# from concurrent.futures import ThreadPoolExecutor
# from dotenv import load_dotenv
# from langchain_google_genai import ChatGoogleGenerativeAI
# from datetime import datetime

# from langchain_core.prompts import PromptTemplate
# from langchain_core.output_parsers import PydanticOutputParser

# from models.pydantic_models import Summary, Mail
# from memory.telegram_conversation import OptimizedConversationManager
# from services.send_email import EmailService
# from services.sql_service import SQLService
# from services.database_manager import get_database_manager
# from utils.prompts import (
#     TEMPLATE_INSTRUCTIONS,
#     EMAIL_TEMPLATE, PROMPT_TEMPLATE
# )

# from services.token_cost_calculator import TokenCostCalculator

# load_dotenv()

# class TelegramLLMService:
#     """Ø®Ø¯Ù…Ø© LLM Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„ØªÙˆØ§Ø² Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¯Ø¹Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ù…Ø¤Ø³Ø³Ø§Øª"""
    
#     def __init__(self, max_workers: int = 10):
#         # LLMs
#         self.llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
#         self.small_llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
        
#         # Parsers
#         self.summary_parser = PydanticOutputParser(pydantic_object=Summary)
#         self.mail_parser = PydanticOutputParser(pydantic_object=Mail)
        
#         # Services
#         self.conversation_manager = OptimizedConversationManager(
#             conversations_dir="logs/conversations",
#             max_conversations=5
#         )
#         self.email_service = EmailService()
        
#         # Database Manager
#         self.db_manager = get_database_manager()
        
#         # Thread Pool Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª blocking
#         self.executor = ThreadPoolExecutor(
#             max_workers=max_workers,
#             thread_name_prefix="LLM_Worker"
#         )
        
#         # Chains
#         self.summary_chain = self._create_summary_chain()
#         self.mail_chain = self._create_mail_chain()
        
#         # Cache for history
#         self._history_cache = {}
#         self._cache_lock = asyncio.Lock()
#         self._cache_timeout = 60
        
#         self.cost_calculator = TokenCostCalculator()
        
#         # ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø±Ø§Ø­Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
#         self._current_conversation_stages = []
    
#     def _create_summary_chain(self):
#         """Ø¥Ù†Ø´Ø§Ø¡ chain Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"""
#         global prompt_summary
#         prompt_summary = PromptTemplate(
#             template=PROMPT_TEMPLATE,
#             input_variables=["schema_text", "history_text", "user_question", "format_instructions"]
#         )
#         return prompt_summary | self.llm | self.summary_parser
    
#     def _create_mail_chain(self):
#         """Ø¥Ù†Ø´Ø§Ø¡ chain Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª"""
#         global prompt_mail
#         prompt_mail = PromptTemplate(
#             template=EMAIL_TEMPLATE,
#             input_variables=["user_question", "sql_result", 
#                            "format_instructions", "history_text", "template_instructions"]
#         )
#         return prompt_mail | self.llm | self.mail_parser
    
#     async def _get_cached_history(self, chat_id: int) -> str:
#         """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ø¹ caching Ø°ÙƒÙŠ"""
#         return await self.conversation_manager.get_cached_history(chat_id)

#     async def _generate_summary(
#         self, 
#         user_question: str, 
#         chat_id: int, 
#         username: str, 
#         timestamp: str,
#         database_id: Optional[str] = None,
#         db_type: Optional[str] = None
#     ) -> Summary:
#         """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ SQL query"""
#         history_text = await self._get_cached_history(chat_id)
        
#         # âœ… Ø¬Ù„Ø¨ Ø§Ù„Ø³ÙƒÙŠÙ…Ø§ ÙˆØ§Ù„Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
#         schema_text = ""
#         data_examples = ""
        
#         if database_id:
#             connection = await self.db_manager.get_connection(database_id)
#             if connection:
#                 schema_text = connection.schema_example or "No schema available"
#                 data_examples = connection.data_example or "No examples available"
#             else:
#                 schema_text = "Database not found"
#                 data_examples = "No examples available"
#         else:
#             schema_text = "No database selected"
#             data_examples = "No examples available"
#         print("Schema Text and Examples:")
#         print(schema_text)
#         print("Schema Examples:")
#         print(data_examples)
        
#         input_data = {
#             "db_type": db_type,
#             "schema_text": schema_text,
#             "data_examples": data_examples,
#             "history_text": history_text,
#             "user_question": user_question,
#             "format_instructions": self.summary_parser.get_format_instructions()
#         }
        
#         loop = asyncio.get_event_loop()
#         input_text = prompt_summary.format(**input_data)
#         input_tokens = await self.cost_calculator.count_tokens(
#             self.llm, 
#             input_text, 
#             self.executor
#         )
        
#         summary = await loop.run_in_executor(
#             self.executor,
#             lambda: self.summary_chain.invoke(input_data)
#         )
        
#         summary_text = str(summary)
#         output_tokens = await self.cost_calculator.count_tokens(
#             self.llm,
#             summary_text,
#             self.executor
#         )
        
#         # print("Summary Generation input - gemini-2.5-flash")
#         # print("input tokens:", input_tokens)
#         print(input_text)
#         # print("Summary Generation output - gemini-2.5-flash")
#         # print("output tokens:", output_tokens)
#         # print(summary_text)
#         stage_data = self.cost_calculator.create_stage_record(
#             stage_number=1,
#             stage_name="Summary Generation",
#             model="gemini-2.5-flash",
#             input_tokens=input_tokens,
#             output_tokens=output_tokens
#         )
        
#         self._current_conversation_stages.append(stage_data)
        
#         return summary, history_text
    
#     async def _process_sql_query(
#         self, 
#         summary: Summary, 
#         user_question: str, 
#         chat_id: int, 
#         username: str, 
#         timestamp: str,
#         database_id: Optional[str] = None
#     ) -> str:
#         """Ù…Ø¹Ø§Ù„Ø¬Ø© SQL query ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""
#         if not summary.sql_query:
#             return summary.answer or "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©"
        
#         if database_id:
#             db = await self.db_manager.get_database_instance(database_id)
#             if not db:
#                 return "âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"
#             sql_service = SQLService(db=db)
#         else:
#             return "âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª"
        
#         # âœ… AFTER:
#         sql_result = await sql_service.execute_async(summary.sql_query)

#         # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø±ÙØ¶ Ø£Ù…Ù†ÙŠ
#         if isinstance(sql_result, str) and "ðŸš« Query rejected" in sql_result:
#             # Ø¥Ø±Ø¬Ø§Ø¹ Ø±Ø³Ø§Ù„Ø© Ø¢Ù…Ù†Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
#             return (
#                 "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…ÙØ·Ù„Ø¨ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø£Ù…Ù†ÙŠØ©.\n"
#                 "ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ù€: SELECT, INSERT, UPDATE"
#             ), sql_result

#         prompt = f"""
# You are a helpful assistant for a Telegram bot.
# Use only the following SQL result to answer the user's question.
# Do not invent, assume, or estimate anything.

# User question: {user_question}
# SQL query: {summary.sql_query}
# SQL result: {sql_result}

# If the SQL result is empty, respond in natural language indicating no records were found.
# Provide a clear and concise answer. Use Arabic or English based on the user's question language.
# Keep the response suitable for Telegram messaging (not too long, well formatted).
# """
                
#         loop = asyncio.get_event_loop()
#         response = await loop.run_in_executor(
#             self.executor,
#             lambda: self.small_llm.invoke(prompt)
#         )
        
#         output_tokens = await self.cost_calculator.count_tokens(
#             self.small_llm,
#             response.content,
#             self.executor
#         )
        
#         input_tokens = await self.cost_calculator.count_tokens(
#             self.small_llm,
#             prompt,
#             self.executor
#         )
#         # print("SQL Response Generation input - gemini-2.0-flash")
#         # print("input tokens:", input_tokens)
#         # print(prompt)
#         # print("SQL Response Generation output - gemini-2.0-flash")
#         # print("output tokens:", output_tokens)
#         # print(response.content)
#         stage_data = self.cost_calculator.create_stage_record(
#             stage_number=2,
#             stage_name="SQL Response Generation",
#             model="gemini-2.0-flash",
#             input_tokens=input_tokens,
#             output_tokens=output_tokens
#         )
        
#         self._current_conversation_stages.append(stage_data)
        
#         return response.content, sql_result
    
#     async def _generate_email(
#         self, 
#         summary: Summary, 
#         user_question: str, 
#         chat_id: int, 
#         username: str, 
#         timestamp: str,
#         database_id: Optional[str] = None,
#         history_text: str = None
#     ) -> Mail:
#         """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„"""
#         tasks = []
        
#         if summary.sql_query and database_id:
#             db = await self.db_manager.get_database_instance(database_id)
#             if db:
#                 sql_service = SQLService(db=db)
#                 # âœ… AFTER:
#                 sql_result = await sql_service.execute_async(summary.sql_query)
#                 # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø±ÙØ¶ Ø£Ù…Ù†ÙŠ
#                 if isinstance(sql_result, str) and "ðŸš« Query rejected" in sql_result:
#                     # Ø¥Ø±Ø¬Ø§Ø¹ Ø±Ø³Ø§Ù„Ø© Ø¢Ù…Ù†Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
#                     return (
#                         "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…ÙØ·Ù„Ø¨ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø£Ù…Ù†ÙŠØ©.\n"
#                         "ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ù€: SELECT, INSERT, UPDATE"
#                     ), sql_result
#             else:
#                 tasks.append(asyncio.sleep(0))
        
#         results = await asyncio.gather(*tasks)
#         sql_result = results[0] if len(results) > 0 else None
        
#         input_data = {
#             "user_question": user_question,
#             "history_text": history_text,
#             "sql_result": sql_result or "",
#             "format_instructions": self.mail_parser.get_format_instructions(),
#             "template_instructions": TEMPLATE_INSTRUCTIONS
#         }
        
#         loop = asyncio.get_event_loop()
#         input_text = prompt_mail.format(**input_data)
#         input_tokens = await self.cost_calculator.count_tokens(
#             self.llm,
#             input_text,
#             self.executor
#         )
        
#         mail = await loop.run_in_executor(
#             self.executor,
#             lambda: self.mail_chain.invoke(input_data)
#         )
        
#         output_tokens = await self.cost_calculator.count_tokens(
#             self.llm,
#             str(mail),
#             self.executor
#         )
#         # print("Email Generation input - gemini-2.5-flash")
#         # print("input tokens:", input_tokens)
#         # print(input_text)
#         # print("Email Generation output - gemini-2.5-flash")
#         # print("output tokens:", output_tokens)
#         # print(str(mail))
#         stage_data = self.cost_calculator.create_stage_record(
#             stage_number=3,
#             stage_name="Email Generation",
#             model="gemini-2.5-flash",
#             input_tokens=input_tokens,
#             output_tokens=output_tokens
#         )
        
#         self._current_conversation_stages.append(stage_data)
        
#         return mail, sql_result
    
#     async def handle_question(
#         self, 
#         user_question: str, 
#         username: str, 
#         chat_id: int,
#         user_id: int = None,
#         database_id: Optional[str] = None,
#         org_id: Optional[str] = None,
#         db_type: Optional[str] = None
#     ) -> Tuple[str, Optional[str], Optional[str], int, Optional[Mail], Optional[str]]:
#         """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø¯Ø¹Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ù…Ø¤Ø³Ø³Ø§Øª"""
#         timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
#         # Ù…Ø³Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
#         self._current_conversation_stages = []
        
#         # Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ
#         summary, history_text = await self._generate_summary(
#             user_question, chat_id, username, timestamp, database_id,db_type
#         )
        
#         answer = None
#         sql_query = summary.sql_query
#         sql_result = None
#         mail = None
        
#         # Ø§Ù„Ø®Ø·ÙˆØ© 2: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
#         if summary.way and summary.way.lower() == "sqlquery":
#             answer, sql_result = await self._process_sql_query(
#                 summary, user_question, chat_id, username, timestamp, database_id
#             )

#         elif summary.way and summary.way.lower() == "email":
#             try:
#                 mail, sql_result = await self._generate_email(
#                     summary, user_question, chat_id, username, timestamp, database_id, history_text
#                 )
                
#                 answer = f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ù„Ù„Ù…Ø±Ø³Ù„ Ø¥Ù„ÙŠÙ‡Ù…: {', '.join(mail.email)}"
#             except Exception as e:
#                 print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„: {e}")
#                 answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
        
#         else:
#             answer = summary.answer or "ØªÙ… Ø§Ù„Ø±Ø¯ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©."
        
#         if answer is None:
#             answer = "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø©"

#         # Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚
#         save_task = self.conversation_manager.save_context(
#             chat_id=chat_id,
#             question=user_question,
#             answer=answer,
#             user_id=user_id,
#             username=username,
#             sql_query=sql_query,
#             sql_result=str(sql_result) if sql_result else "None",
#         )
        
#         memory_task = self.conversation_manager.get_memory_length(chat_id)
        
#         await save_task
#         history_len = await memory_task
        
#         # Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø¤Ø³Ø³Ø© ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
#         conversation_id = self.cost_calculator.save_conversation(
#             chat_id=chat_id,
#             user_id=user_id,
#             username=username,
#             user_question=user_question,
#             org_id=org_id,
#             database_id=database_id
#         )
        
#         # Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
#         if self._current_conversation_stages and conversation_id:
#             total_input_tokens = sum(s["input_tokens"] for s in self._current_conversation_stages)
#             total_output_tokens = sum(s["output_tokens"] for s in self._current_conversation_stages)
#             total_tokens = sum(s["total_tokens"] for s in self._current_conversation_stages)
#             total_input_cost = sum(float(s["cost"]["input"]) for s in self._current_conversation_stages)
#             total_output_cost = sum(float(s["cost"]["output"]) for s in self._current_conversation_stages)
#             total_cost = sum(float(s["cost"]["total"]) for s in self._current_conversation_stages)
            
#             # âœ… Ø­ÙØ¸ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© Ø¹Ù„Ù‰ Ø­Ø¯Ø©
#             for stage in self._current_conversation_stages:
#                 self.cost_calculator.save_stage(
#                     conversation_id=conversation_id,
#                     chat_id=chat_id,
#                     stage_number=stage["stage_number"],
#                     stage_name=stage["stage_name"],
#                     model=stage["model"],
#                     input_tokens=stage["input_tokens"],
#                     output_tokens=stage["output_tokens"],
#                     total_tokens=stage["total_tokens"],
#                     input_cost=float(stage["cost"]["input"]),
#                     output_cost=float(stage["cost"]["output"]),
#                     total_cost=float(stage["cost"]["total"])
#                 )
            
#             # âœ… Ø­ÙØ¸ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
#             self.cost_calculator.save_conversation_summary(
#                 conversation_id=conversation_id,
#                 chat_id=chat_id,
#                 total_stages=len(self._current_conversation_stages),
#                 input_tokens=total_input_tokens,
#                 output_tokens=total_output_tokens,
#                 total_tokens=total_tokens,
#                 input_cost=total_input_cost,
#                 output_cost=total_output_cost,
#                 total_cost=total_cost,
#                 stages=self._current_conversation_stages
#             )
            
#             # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
#             for stage in self._current_conversation_stages:
#                 self.cost_calculator.update_model_usage(
#                     chat_id=chat_id,
#                     model=stage["model"],
#                     input_tokens=stage["input_tokens"],
#                     output_tokens=stage["output_tokens"],
#                     total_tokens=stage["total_tokens"],
#                     input_cost=float(stage["cost"]["input"]),
#                     output_cost=float(stage["cost"]["output"]),
#                     total_cost=float(stage["cost"]["total"]),
#                     org_id=org_id
#                 )
            
#             # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ø­Ù„
#             for stage in self._current_conversation_stages:
#                 self.cost_calculator.update_stage_usage(
#                     chat_id=chat_id,
#                     stage_name=stage["stage_name"],
#                     input_tokens=stage["input_tokens"],
#                     output_tokens=stage["output_tokens"],
#                     total_tokens=stage["total_tokens"],
#                     input_cost=float(stage["cost"]["input"]),
#                     output_cost=float(stage["cost"]["output"]),
#                     total_cost=float(stage["cost"]["total"]),
#                     org_id=org_id
#                 )
            
            
#             # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ù„Ù„ØªÙˆÙƒÙ†Ø§Øª ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ
#             # print(f"\nðŸ“Š Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª:")
#             # print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª: {total_tokens}")
#             # print(f"   â€¢ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ:")
#             # print(f"     - Input: ${total_input_cost:.8f}")
#             # print(f"     - Output: ${total_output_cost:.8f}")
#             # print(f"     - Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: ${total_cost:.8f}")
#             # print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø­Ù„: {len(self._current_conversation_stages)}")
#             if org_id:
#                 print(f"   â€¢ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©: {org_id}")
#             if database_id:
#                 print(f"   â€¢ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {database_id}")
#             print()

#         return answer, sql_query, sql_result, history_len, mail

#     async def send_email(self, mail: Mail) -> str:
#         """Ø¥Ø±Ø³Ø§Ù„ Ø¥ÙŠÙ…ÙŠÙ„ Ø¨Ø´ÙƒÙ„ async"""
#         return await self.email_service.send_async(
#             subject=mail.subject,
#             body=mail.body,
#             recipients=mail.email
#         )
    
#     async def cleanup(self):
#         """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
#         await self.conversation_manager.stop_writer()
#         self.executor.shutdown(wait=True)


# # Singleton instance
# _llm_service = None

# def get_llm_service() -> TelegramLLMService:
#     """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ instance ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø©"""
#     global _llm_service
#     if _llm_service is None:
#         _llm_service = TelegramLLMService(max_workers=10)
#     return _llm_service



# services/telegram_llm_service.py
# Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯

import asyncio
from typing import Tuple, Optional
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from datetime import datetime

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

from models.pydantic_models import Summary, Mail
# âœ… ØªØ­Ø¯ÙŠØ«: Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯
from memory.telegram_conversation import OptimizedConversationManager
from services.send_email import EmailService
from services.sql_service import SQLService
from services.database_manager import get_database_manager
from utils.prompts import (
    TEMPLATE_INSTRUCTIONS,
    EMAIL_TEMPLATE, PROMPT_TEMPLATE
)

from services.token_cost_calculator import TokenCostCalculator

load_dotenv()

class TelegramLLMService:
    """Ø®Ø¯Ù…Ø© LLM Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„ØªÙˆØ§Ø²ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¯Ø¹Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ù…Ø¤Ø³Ø³Ø§Øª"""
    
    def __init__(self, max_workers: int = 10):
        # LLMs
        self.llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
        self.small_llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
        
        # Parsers
        self.summary_parser = PydanticOutputParser(pydantic_object=Summary)
        self.mail_parser = PydanticOutputParser(pydantic_object=Mail)
        
        # âœ… ØªØ­Ø¯ÙŠØ«: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ SQL
        self.conversation_manager = OptimizedConversationManager(
            db_url="mssql+pyodbc://@B515R\\SQLEXPRESS/conversations?driver=ODBC+Driver+17+for+SQL+Server"
        )
        
        # Services
        self.email_service = EmailService()
        
        # Database Manager
        self.db_manager = get_database_manager()
        
        # Thread Pool Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª blocking
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix="LLM_Worker"
        )
        
        # Chains
        self.summary_chain = self._create_summary_chain()
        self.mail_chain = self._create_mail_chain()
        
        self.cost_calculator = TokenCostCalculator()
        
        # ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø±Ø§Ø­Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        self._current_conversation_stages = []
    
    async def startup(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
        try:
            await self.conversation_manager.initialize()
            print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
            raise
    
    def _create_summary_chain(self):
        """Ø¥Ù†Ø´Ø§Ø¡ chain Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"""
        global prompt_summary
        prompt_summary = PromptTemplate(
            template=PROMPT_TEMPLATE,
            input_variables=["schema_text", "history_text", "user_question", "format_instructions"]
        )
        return prompt_summary | self.llm | self.summary_parser
    
    def _create_mail_chain(self):
        """Ø¥Ù†Ø´Ø§Ø¡ chain Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª"""
        global prompt_mail
        prompt_mail = PromptTemplate(
            template=EMAIL_TEMPLATE,
            input_variables=["user_question", "sql_result", 
                           "format_instructions", "history_text", "template_instructions"]
        )
        return prompt_mail | self.llm | self.mail_parser
    
    async def _get_cached_history(self, chat_id: int) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ø¹ caching Ø°ÙƒÙŠ"""
        return await self.conversation_manager.get_cached_history(chat_id)

    async def _generate_summary(
        self, 
        user_question: str, 
        chat_id: int, 
        username: str, 
        timestamp: str,
        database_id: Optional[str] = None,
        db_type: Optional[str] = None
    ) -> Summary:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ SQL query"""
        history_text = await self._get_cached_history(chat_id)
        
        # âœ… Ø¬Ù„Ø¨ Ø§Ù„Ø³ÙƒÙŠÙ…Ø§ ÙˆØ§Ù„Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        schema_text = ""
        data_examples = ""
        
        if database_id:
            connection = await self.db_manager.get_connection(database_id)
            if connection:
                schema_text = connection.schema_example or "No schema available"
                data_examples = connection.data_example or "No examples available"
            else:
                schema_text = "Database not found"
                data_examples = "No examples available"
        else:
            schema_text = "No database selected"
            data_examples = "No examples available"
        print("Schema Text and Examples:")
        print(schema_text)
        print("Schema Examples:")
        print(data_examples)
        
        input_data = {
            "db_type": db_type,
            "schema_text": schema_text,
            "data_examples": data_examples,
            "history_text": history_text,
            "user_question": user_question,
            "format_instructions": self.summary_parser.get_format_instructions()
        }
        
        loop = asyncio.get_event_loop()
        input_text = prompt_summary.format(**input_data)
        input_tokens = await self.cost_calculator.count_tokens(
            self.llm, 
            input_text, 
            self.executor
        )
        
        summary = await loop.run_in_executor(
            self.executor,
            lambda: self.summary_chain.invoke(input_data)
        )
        
        summary_text = str(summary)
        output_tokens = await self.cost_calculator.count_tokens(
            self.llm,
            summary_text,
            self.executor
        )
        
        # print(input_text)
        stage_data = self.cost_calculator.create_stage_record(
            stage_number=1,
            stage_name="Summary Generation",
            model="gemini-2.5-flash",
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        self._current_conversation_stages.append(stage_data)
        
        return summary, history_text
    
    async def _process_sql_query(
        self, 
        summary: Summary, 
        user_question: str, 
        chat_id: int, 
        username: str, 
        timestamp: str,
        database_id: Optional[str] = None
    ) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© SQL query ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""
        if not summary.sql_query:
            return summary.answer or "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©"
        
        if database_id:
            db = await self.db_manager.get_database_instance(database_id)
            if not db:
                return "âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"
            sql_service = SQLService(db=db)
        else:
            return "âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª"
        
        # âœ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
        sql_result = await sql_service.execute_async(summary.sql_query)

        # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø±ÙØ¶ Ø£Ù…Ù†ÙŠ
        if isinstance(sql_result, str) and "ðŸš« Query rejected" in sql_result:
            return (
                "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø£Ù…Ù†ÙŠØ©.\n"
                "ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ù€: SELECT, INSERT, UPDATE"
            ), sql_result

        prompt = f"""
You are a helpful assistant for a Telegram bot.
Use only the following SQL result to answer the user's question.
Do not invent, assume, or estimate anything.

User question: {user_question}
SQL query: {summary.sql_query}
SQL result: {sql_result}

If the SQL result is empty, respond in natural language indicating no records were found.
Provide a clear and concise answer. Use Arabic or English based on the user's question language.
Keep the response suitable for Telegram messaging (not too long, well formatted).
"""
                
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            self.executor,
            lambda: self.small_llm.invoke(prompt)
        )
        
        output_tokens = await self.cost_calculator.count_tokens(
            self.small_llm,
            response.content,
            self.executor
        )
        
        input_tokens = await self.cost_calculator.count_tokens(
            self.small_llm,
            prompt,
            self.executor
        )
        
        stage_data = self.cost_calculator.create_stage_record(
            stage_number=2,
            stage_name="SQL Response Generation",
            model="gemini-2.0-flash",
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        self._current_conversation_stages.append(stage_data)
        
        return response.content, sql_result
    
    async def _generate_email(
        self, 
        summary: Summary, 
        user_question: str, 
        chat_id: int, 
        username: str, 
        timestamp: str,
        database_id: Optional[str] = None,
        history_text: str = None
    ) -> Mail:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„"""
        tasks = []
        
        if summary.sql_query and database_id:
            db = await self.db_manager.get_database_instance(database_id)
            if db:
                sql_service = SQLService(db=db)
                # âœ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
                sql_result = await sql_service.execute_async(summary.sql_query)
                # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø±ÙØ¶ Ø£Ù…Ù†ÙŠ
                if isinstance(sql_result, str) and "ðŸš« Query rejected" in sql_result:
                    return (
                        "âš ï¸ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø£Ù…Ù†ÙŠØ©.\n"
                        "ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ù€: SELECT, INSERT, UPDATE"
                    ), sql_result
            else:
                tasks.append(asyncio.sleep(0))
        
        results = await asyncio.gather(*tasks)
        sql_result = results[0] if len(results) > 0 else None
        
        input_data = {
            "user_question": user_question,
            "history_text": history_text,
            "sql_result": sql_result or "",
            "format_instructions": self.mail_parser.get_format_instructions(),
            "template_instructions": TEMPLATE_INSTRUCTIONS
        }
        
        loop = asyncio.get_event_loop()
        input_text = prompt_mail.format(**input_data)
        input_tokens = await self.cost_calculator.count_tokens(
            self.llm,
            input_text,
            self.executor
        )
        
        mail = await loop.run_in_executor(
            self.executor,
            lambda: self.mail_chain.invoke(input_data)
        )
        
        output_tokens = await self.cost_calculator.count_tokens(
            self.llm,
            str(mail),
            self.executor
        )
        
        stage_data = self.cost_calculator.create_stage_record(
            stage_number=3,
            stage_name="Email Generation",
            model="gemini-2.5-flash",
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        self._current_conversation_stages.append(stage_data)
        
        return mail, sql_result
    
    async def handle_question(
        self, 
        user_question: str, 
        username: str, 
        chat_id: int,
        user_id: int = None,
        database_id: Optional[str] = None,
        org_id: Optional[str] = None,
        db_type: Optional[str] = None
    ) -> Tuple[str, Optional[str], Optional[str], int, Optional[Mail], Optional[str]]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø¯Ø¹Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ù…Ø¤Ø³Ø³Ø§Øª"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Ù…Ø³Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self._current_conversation_stages = []
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ
        summary, history_text = await self._generate_summary(
            user_question, chat_id, username, timestamp, database_id, db_type
        )
        
        answer = None
        sql_query = summary.sql_query
        sql_result = None
        mail = None
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 2: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        if summary.way and summary.way.lower() == "sqlquery":
            answer, sql_result = await self._process_sql_query(
                summary, user_question, chat_id, username, timestamp, database_id
            )

        elif summary.way and summary.way.lower() == "email":
            try:
                mail, sql_result = await self._generate_email(
                    summary, user_question, chat_id, username, timestamp, database_id, history_text
                )
                
                answer = f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ù„Ù„Ù…Ø±Ø³Ù„ Ø¥Ù„ÙŠÙ‡Ù…: {', '.join(mail.email)}"
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„: {e}")
                answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
        
        else:
            answer = summary.answer or "ØªÙ… Ø§Ù„Ø±Ø¯ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©."
        
        if answer is None:
            answer = "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø©"

        # Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚
        # âœ… ØªØ­Ø¯ÙŠØ«: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
        await self.conversation_manager.save_context(
            chat_id=chat_id,
            question=user_question,
            answer=answer,
            user_id=user_id,
            username=username,
            sql_query=sql_query,
            sql_result=str(sql_result) if sql_result else None,
            database_id=database_id,  # ðŸ†•
            db_type=db_type  # ðŸ†•
        )
        
        history_len = await self.conversation_manager.get_memory_length(chat_id)
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ù…Ø¹Ø±Ù‘Ù Ø§Ù„Ù…Ø¤Ø³Ø³Ø© ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        conversation_id = self.cost_calculator.save_conversation(
            chat_id=chat_id,
            user_id=user_id,
            username=username,
            user_question=user_question,
            org_id=org_id,
            database_id=database_id
        )
        
        # Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        if self._current_conversation_stages and conversation_id:
            total_input_tokens = sum(s["input_tokens"] for s in self._current_conversation_stages)
            total_output_tokens = sum(s["output_tokens"] for s in self._current_conversation_stages)
            total_tokens = sum(s["total_tokens"] for s in self._current_conversation_stages)
            total_input_cost = sum(float(s["cost"]["input"]) for s in self._current_conversation_stages)
            total_output_cost = sum(float(s["cost"]["output"]) for s in self._current_conversation_stages)
            total_cost = sum(float(s["cost"]["total"]) for s in self._current_conversation_stages)
            
            # âœ… Ø­ÙØ¸ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© Ø¹Ù„Ù‰ Ø­Ø¯Ø©
            for stage in self._current_conversation_stages:
                self.cost_calculator.save_stage(
                    conversation_id=conversation_id,
                    chat_id=chat_id,
                    stage_number=stage["stage_number"],
                    stage_name=stage["stage_name"],
                    model=stage["model"],
                    input_tokens=stage["input_tokens"],
                    output_tokens=stage["output_tokens"],
                    total_tokens=stage["total_tokens"],
                    input_cost=float(stage["cost"]["input"]),
                    output_cost=float(stage["cost"]["output"]),
                    total_cost=float(stage["cost"]["total"])
                )
            
            # âœ… Ø­ÙØ¸ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            self.cost_calculator.save_conversation_summary(
                conversation_id=conversation_id,
                chat_id=chat_id,
                total_stages=len(self._current_conversation_stages),
                input_tokens=total_input_tokens,
                output_tokens=total_output_tokens,
                total_tokens=total_tokens,
                input_cost=total_input_cost,
                output_cost=total_output_cost,
                total_cost=total_cost,
                stages=self._current_conversation_stages
            )
            
            # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            for stage in self._current_conversation_stages:
                self.cost_calculator.update_model_usage(
                    chat_id=chat_id,
                    model=stage["model"],
                    input_tokens=stage["input_tokens"],
                    output_tokens=stage["output_tokens"],
                    total_tokens=stage["total_tokens"],
                    input_cost=float(stage["cost"]["input"]),
                    output_cost=float(stage["cost"]["output"]),
                    total_cost=float(stage["cost"]["total"]),
                    org_id=org_id
                )
            
            # âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ø­Ù„
            for stage in self._current_conversation_stages:
                self.cost_calculator.update_stage_usage(
                    chat_id=chat_id,
                    stage_name=stage["stage_name"],
                    input_tokens=stage["input_tokens"],
                    output_tokens=stage["output_tokens"],
                    total_tokens=stage["total_tokens"],
                    input_cost=float(stage["cost"]["input"]),
                    output_cost=float(stage["cost"]["output"]),
                    total_cost=float(stage["cost"]["total"]),
                    org_id=org_id
                )

        return answer, sql_query, sql_result, history_len, mail

    async def send_email(self, mail: Mail) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø¥ÙŠÙ…ÙŠÙ„ Ø¨Ø´ÙƒÙ„ async"""
        return await self.email_service.send_async(
            subject=mail.subject,
            body=mail.body,
            recipients=mail.email
        )
    
    async def cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        await self.conversation_manager.cleanup()
        self.executor.shutdown(wait=True)


# Singleton instance
_llm_service = None

def get_llm_service() -> TelegramLLMService:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ instance ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø©"""
    global _llm_service
    if _llm_service is None:
        _llm_service = TelegramLLMService(max_workers=10)
    return _llm_service